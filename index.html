
<audio autoplay controls></audio>

<div id="buttons">
    <button onclick="start()" id="start">Start</button>
    <button onclick="stop()" id="stop" disabled>Stop</button>
</div>

<script src="https://webrtc.github.io/adapter/adapter-latest.js"></script>

<script>

const tabId = Math.random().toString(36).substr(2);

class Metronome {

  constructor() {
    window.AudioContext = window.AudioContext;
    this.context = new AudioContext();
    this.soundBuffer = null;
  }

  stream() {
    this.peer = this.context.createMediaStreamDestination();
    return this.peer.stream;
  }

  stop() {
    this.peer = null;
  }

  bong() {
    let effect = this.context.createBufferSource();
    effect.buffer = this.soundBuffer;
    if (this.peer) {
      effect.connect(this.peer);
      effect.start(0);
    }
  }

  load(url) {
    this.request = new XMLHttpRequest();
    this.request.open('GET', url + "?w=" + Math.random().toString(36), true);
    this.request.responseType = 'arraybuffer';
    this.request.onload = () => {
      this.context.decodeAudioData(this.request.response, buffer => {
        this.soundBuffer = buffer;
      });
    };
    this.request.send();
  }

}

const audioElement = document.querySelector('audio');
const startButton = document.querySelector('button#start');
const stopButton = document.querySelector('button#stop');

let pc1, pc2;

const metronome = new Metronome;
metronome.load('tick.wav?c=' + Math.random().toString(36).substring(7));

function start() {
  startStream();
  startButton.disabled = true;
  stopButton.disabled = false;
}

function stop() {
  startButton.disabled = false;
  stopButton.disabled = true;
  metronome.stop();
  pc1.close();
  pc2.close();
  pc1 = null;
  pc2 = null;
}

function startStream() {
  const stream = metronome.stream();
  const servers = null;
  pc1 = new RTCPeerConnection(servers);
  pc1.onicecandidate = e => onIceCandidate(pc1, e);
  pc2 = new RTCPeerConnection(servers);
  pc2.onicecandidate = e => onIceCandidate(pc2, e);
  pc2.ontrack = gotRemoteStream;
  stream.getTracks().forEach(track => pc1.addTrack(track, stream));
  pc1.createOffer().then(gotDescription1).catch(error => console.warn);
}

const tabStates = {};

const channel = new BroadcastChannel('tabby');
channel.onmessage = async function(e) {
  const message = e.data;
  if (message.load) {
    tabStates[message.load] = 'loaded';
  }
  if (message.tabclose) {
    delete tabStates[message.tabclose];
    // notify other tabs that we've stopped our audio track
    const clonedStream = audioElement.srcObject.clone();
    audioElement.srcObject.getTracks().forEach(t => t.stop());
    channel.postMessage({ stoppedAudio: tabId });
    const resumeIv = setInterval(async _ => {
      // wait for all open tabs to be stopped
      if (Object.values(tabStates).find(state => state !== 'stopped')) {
        return;
      }

      clearInterval(resumeIv);

      // resume audio
      audioElement.srcObject = clonedStream;
      await audioElement.play();

      // broadcast our recovered state
      channel.postMessage({ load: tabId });
    }, 10);
  }
  if (message.stoppedAudio) {
    tabStates[message.stoppedAudio] = 'stopped';
  }
};

window.addEventListener('unload', function(event) {
  channel.postMessage({ tabclose: tabId });
  metronome.stop();
  pc1.close();
  pc2.close();
  pc1 = null;
  pc2 = null;
  console.log('I am the 2nd one.');
});

window.addEventListener('load', function(event) {
  channel.postMessage({ load: tabId });
});

function gotDescription1(desc) {
  pc1.setLocalDescription(desc);
  pc2.setRemoteDescription(desc);
  pc2.createAnswer()
    .then(gotDescription2)
    .catch(error => console.warn);
}

function gotDescription2(desc) {
  pc2.setLocalDescription(desc);
  pc1.setRemoteDescription(desc);
}

function gotRemoteStream(e) {
  if (audioElement.srcObject !== e.streams[0]) {
    audioElement.srcObject = e.streams[0];
  }
}

function onIceCandidate(pc, event) {
  (pc == pc1 ? pc2 : pc1)
    .addIceCandidate(event.candidate)
    .then();
}

setInterval(_ => metronome.bong(), 1000);

</script>
